# Pinot managed Offline flows

{% hint style="info" %}
**Original design doc**: [https://docs.google.com/document/d/1-e\_9aHQB4HXS38ONtofdxNvMsGmAoYfSnc2LP88MbIc/edit\#](https://docs.google.com/document/d/1-e_9aHQB4HXS38ONtofdxNvMsGmAoYfSnc2LP88MbIc/edit#)

**Issue**: [https://github.com/apache/incubator-pinot/issues/5753](https://github.com/apache/incubator-pinot/issues/5753)
{% endhint %}

The Pinot managed offline flows feature allows a user to **simply setup a REALTIME table, and let Pinot manage populating the OFFLINE table**. For complete motivation and reasoning, please refer to the design doc above.

### When to use

There are 3 kinds of tables in Pinot

* **OFFLINE only** - this feature is not relevant for this mode.
* **REALTIME only** - this feature is built for this mode. While having a realtime-only table setup \(versus a hybrid table setup\) is certainly lightweight and lesser operations, you lose some of the flexibility that comes with having a corresponding OFFLINE table. 

  * For example, in realtime only mode, it is impossible to backfill a specific day's data, even if you have that data available offline somewhere, whereas you could've easily run a one off backfill job to correct data in an OFFLINE table. 
  * It is also not possible to re-bootstrap the table using some offline data, as data for the REALTIME table strictly must come in through a stream. In OFFLINE tables, it is very easy to run jobs and replace segments in the table.
  * In REALTIME tables, the data often tends to be highly granular and we achieve very little aggregations. OFFLINE tables let you look at bigger windows of data hence achieving rollups for time column, aggregations across common dimensions, better compression and even dedup.

  This feature will **automatically manage the movement of the data to a corresponding OFFLINE table, so you don't have to write any offline jobs.** 

* **HYBRID table** - If you already have a hybrid table this feature again may not be relevant to you. But you could explore using this to replace your offline push jobs, and simply keep them for backfills.

### How this works

The Pinot managed offline flows feature will **move records from the REALTIME table to the OFFLINE table, one `time window` at a time**. For example, if the REALTIME table has records with timestamp starting 10-24-2020T13:56:00, then the Pinot managed offline flows will move records for the time window \[10-24-2020, 10-25-2020\) in the first run, followed by \[10-25-2020, 10-26-1010\) in the next run, followed by \[10-26-2020, 10-27-2020\) in the next run, and so on. This **window length** of 1d is just the default, and it can be configured to any length of your choice.  

This feature uses the **pinot-minions** and **the Helix Task Executor framework**. This feature consists of 2 parts

![RealtimeToOfflineSegmentsTask](../../.gitbook/assets/paper.journal.15.png)

1. **RealtimeToOfflineSegmentsTaskGenerator** - This is the minion task scheduler, which schedules tasks of type "**RealtimeToOfflineSegmentsTask**". This task is scheduled by the controller periodic task - **PinotTaskManager**. A **watermark is maintained in zookeeper**, which is the end time of the time window last successfully processed. The task generator  refers to this watermark, to determine the start of the time window, for the next task it generates. The end time is calculated based on the window length \(configurable, 1d default\). The task generator will find all segments which have data in \[start, end\), and set it into the **task configs**, along with the start and end. The generator will not schedule a new task, unless the previous task has COMPLETED \(or been stuck for over 24h\). This is to ensure that we always move records in sequential time windows \(exactly mimicking offline flows\), because out-of-order data pushes will mess with the time boundary calculation of the hybrid table.
2. **RealtimeToOfflineSegmentsTaskExecutor** - This is a minion task executor to execute the RealtimeToOfflineSegmentsTask generated by the task generator. These **tasks are run by the pinot-minion** component.  The task executor will download all segments from the REALTIME table, as indicated in the task config. Using the SegmentProcessorFramework, it will **extract data for \[start, end\), build the segments, and push them to the OFFLINE table**. The segment processor framework will **do any required partitioning & sorting based on the OFFLINE table config**. Before exiting from the task, it will **update the watermark in zookeeper**, to reflect the end time of the time window processed.

### Config

**Step 0:** Start a pinot-minion

**Step 1**: Setup your REALTIME table. Add "RealtimeToOfflineSegmentsTask" in the task configs

```text
"tableName": "myTable_REALTIME",
"tableType": "REALTIME",
...
...
"task": {
    "taskTypeConfigsMap": {
      "RealtimeToOfflineSegmentsTask": {
      }
    }
  }
```

**Step 2**: Create the corresponding OFFLINE table

**Step 3**: Enable PinotTaskManager

The PinotTaskManager periodic task is disabled by default. Enable it by adding this property to your controller conf. Set the frequency to some reasonable value \(frequently is better, as extra tasks will not be scheduled unless required\). Controller will need a restart after setting this config.

```text
"controller.task.frequencyInSeconds": 3600
```

**Step 4**: Advanced configs

If needed, you can add more configs to the task configs in the REALTIME table, such as

```text
"task": {
    "taskTypeConfigsMap": {
      "RealtimeToOfflineSegmentsTask": {
        "bucketTimePeriod": "6h",
        "bufferTimePeriod": "5d",
        "roundBucketTimePeriod": "1h",
        "mergeType": "rollup",
        "score.aggregationType": "max",
        "maxNumRecordsPerSegment": "100000"
      }
    }
  }
```

where,

<table>
  <thead>
    <tr>
      <th style="text-align:left">Property</th>
      <th style="text-align:left">Description</th>
      <th style="text-align:left">Default</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align:left">bucketTimePeriod</td>
      <td style="text-align:left"><b>Time window size</b> for each run. Adjust this to change the time window.
        E.g. if set to 1h, each task will process 1h data at a time.</td>
      <td style="text-align:left">1d</td>
    </tr>
    <tr>
      <td style="text-align:left">bufferTimePeriod</td>
      <td style="text-align:left">
        <p><b>Buffer time</b>. Will not schedule tasks unless time window is older
          than this buffer.
          <br />Configure this according to how late you expect your data. E.g. if your
          system can emit events later than 3d, set this to 3d to make sure those
          are included.</p>
        <p>Note: Once a given time window has been processed, it will never be processed
          again.</p>
      </td>
      <td style="text-align:left">2d</td>
    </tr>
    <tr>
      <td style="text-align:left">
        <p>roundBucketTimePeriod</p>
        <p>(supported since release <code>0.8.0</code>)</p>
      </td>
      <td style="text-align:left"><b>Round the time value before merging the rows</b>. This is useful if
        time column is highly granular in the REALTIME table and is not needed
        by the application. In the OFFLINE table you can rollup the time values
        (e.g. milliseconds granularity in REALTIME table, but okay with minute
        level granularity in the application - set to <code>1m</code>
      </td>
      <td style="text-align:left">None</td>
    </tr>
    <tr>
      <td style="text-align:left">
        <p>mergeType</p>
        <p>(supported since release <code>0.8.0</code>)</p>
      </td>
      <td style="text-align:left">Allowed values are
        <br /><b>concat</b> - no aggregations
        <br /><b>rollup</b> - perform metrics aggregations across common dimensions +
        time
        <br /><b>dedup</b> - deduplicates rows with the same values</td>
      <td style="text-align:left">concat</td>
    </tr>
    <tr>
      <td style="text-align:left">{metricName}.aggregationType</td>
      <td style="text-align:left"><b>Aggregation function to apply to the metric</b> for aggregations. Only
        applicable for <code>rollup</code> case. Allowed values are <code>sum</code>, <code>max</code>, <code>min</code>
      </td>
      <td style="text-align:left">sum</td>
    </tr>
    <tr>
      <td style="text-align:left">maxNumRecordsPerSegment</td>
      <td style="text-align:left">Control the <b>number of records you want in a segment generated</b>. Useful
        if the time window has many records, but you don&apos;t want them all in
        the same segment.</td>
      <td style="text-align:left">1,000,000</td>
    </tr>
  </tbody>
</table>

{% hint style="warning" %}
The following properties are deprecated/removed in release `0.8.0`

* **timeColumnTransformFunction** \(removed\): Use [ingestion transforms](../../developers/advanced/ingestion-level-transformations.md) or **roundBucketTimePeriod** instead
* **collectorType** \(deprecated\): Replaced by **mergeType**
{% endhint %}

### **Limitations & possible enhancements**

#### **Late data problem**

Once the time window has moved forward, it will never be processed again. If some data arrives into your stream after the window has moved on, that data will never be processed. Set the "bufferTimePeriod" accordingly, to account for late data issues in your setup.  
We will potentially consider ability to schedule ad-hoc one-off tasks. For example, user can specify "rerun for day 10/23", which would sweep all segments again and collect data, replacing the old segments. This will help resolve the problem of data arriving very late.

#### Backfill/bootstrap

This feature automates the daily/hourly pushes to the offline counterpart of your hybrid table. And since you now have an OFFLINE table created, it opens up the possibility of doing an ad-hoc backfill or re-bootstrap. However, there are no mechanisms for doing an automated backfill/re-bootstrap from some offline data. You still have to write your own flows for such scenarios. 

#### Memory constraints

The segments download, data extraction, transformation, aggregations, sorting all happens on a single minion node for every run. You will need to be mindful of the memory available on the minion machine. Adjust the `bucketSize` and `maxNumRecordsPerSegment` if you are running into memory issues.  
We will potentially introduce smarter config adjustments based on memory, or consider using Spark/Hadoop MR.

  


